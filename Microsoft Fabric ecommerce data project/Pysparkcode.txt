BRONZE LAYER - 
# Load messy CSVs
path = "/lakehouse/default/Files/raw/customer360/"

customers_raw = spark.read.option("header", True).csv(path + "customers.csv")
orders_raw = spark.read.option("header", True).csv(path + "orders.csv")
payments_raw = spark.read.option("header", True).csv(path + "payments.csv")
support_raw = spark.read.option("header", True).csv(path + "support_tickets.csv")
web_raw = spark.read.option("header", True).csv(path + "web_activities.csv")

# Save as Bronze Delta Tables
customers_raw.write.format("delta").mode("overwrite").saveAsTable("bronze.customers")
orders_raw.write.format("delta").mode("overwrite").saveAsTable("bronze.orders")
payments_raw.write.format("delta").mode("overwrite").saveAsTable("bronze.payments")
support_raw.write.format("delta").mode("overwrite").saveAsTable("bronze.support")
web_raw.write.format("delta").mode("overwrite").saveAsTable("bronze.web")


Silver Layer â€“ Clean & Normalize

from pyspark.sql.functions import *
from pyspark.sql.types import DoubleType

# Clean customers
customers = spark.table("bronze.customers")

customers_clean = (
    customers
    .withColumn("email", lower(trim(col("EMAIL"))))
    .withColumn("name", initcap(trim(col("name"))))
    .withColumn("gender", when(lower(col("gender")).isin("f", "female"), "Female")
                          .when(lower(col("gender")).isin("m", "male"), "Male")
                          .otherwise("Other"))
    .withColumn("dob", to_date(regexp_replace(col("dob"), "/", "-")))
    .withColumn("location", initcap(col("location")))
    .dropDuplicates(["customer_id"])
    .dropna(subset=["customer_id", "email"])
)
customers_clean.write.format("delta").mode("overwrite").saveAsTable("silver.customers")

# Clean orders
orders = spark.table("bronze.orders")
orders_clean = (
    orders
    .withColumn("order_date", 
                when(col("order_date").rlike("^\d{4}/\d{2}/\d{2}$"), to_date(col("order_date"), "yyyy/MM/dd"))
                .when(col("order_date").rlike("^\d{2}-\d{2}-\d{4}$"), to_date(col("order_date"), "dd-MM-yyyy"))
                .when(col("order_date").rlike("^\d{8}$"), to_date(col("order_date"), "yyyyMMdd"))
                .otherwise(to_date(col("order_date"), "yyyy-MM-dd")))
    .withColumn("amount", col("amount").cast(DoubleType()))
    .withColumn("amount", when(col("amount") < 0, None).otherwise(col("amount")))
    .withColumn("status", initcap(col("status")))
    .dropna(subset=["customer_id", "order_date"])
    .dropDuplicates(["order_id"])
)
orders_clean.write.format("delta").mode("overwrite").saveAsTable("silver.orders")

# Clean payments
payments = spark.table("bronze.payments")
payments_clean = (
    payments
    .withColumn("payment_date", to_date(regexp_replace(col("payment_date"), "/", "-")))
    .withColumn("payment_method", initcap(col("payment_method")))
    .replace({"creditcard": "Credit Card"}, subset=["payment_method"])
    .withColumn("payment_status", initcap(col("payment_status")))
    .withColumn("amount", col("amount").cast(DoubleType()))
    .withColumn("amount", when(col("amount") < 0, None).otherwise(col("amount")))
    .dropna(subset=["customer_id", "payment_date", "amount"])
)
payments_clean.write.format("delta").mode("overwrite").saveAsTable("silver.payments")

# Clean support
support = spark.table("bronze.support")
support_clean = (
    support
    .withColumn("ticket_date", to_date(regexp_replace(col("ticket_date"), "/", "-")))
    .withColumn("issue_type", initcap(trim(col("issue_type"))))
    .withColumn("resolution_status", initcap(trim(col("resolution_status"))))
    .replace({"NA": None, "": None}, subset=["issue_type", "resolution_status"])
    .dropDuplicates(["ticket_id"])
    .dropna(subset=["customer_id", "ticket_date"])
)
support_clean.write.format("delta").mode("overwrite").saveAsTable("silver.support")

# Clean web
web = spark.table("bronze.web")
web_clean = (
    web
    .withColumn("session_time", to_date(regexp_replace(col("session_time"), "/", "-")))
    .withColumn("page_viewed", lower(col("page_viewed")))
    .withColumn("device_type", initcap(col("device_type")))
    .dropDuplicates(["session_id"])
    .dropna(subset=["customer_id", "session_time", "page_viewed"])
)
web_clean.write.format("delta").mode("overwrite").saveAsTable("silver.web")


-----GOLD 

cust = spark.table("silver.customers").alias("c")
orders = spark.table("silver.orders").alias("o")
payments = spark.table("silver.payments").alias("p")
support = spark.table("silver.support").alias("s")
web = spark.table("silver.web").alias("w")

customer360 = (
    cust
    .join(orders, "customer_id", "left")
    .join(payments, "customer_id", "left")
    .join(support, "customer_id", "left")
    .join(web, "customer_id", "left")
    .select(
        "c.customer_id", "c.name", "c.email", "c.gender", "c.dob", "c.location",
        "o.order_id", "o.order_date", "o.amount", "o.status",
        "p.payment_method", "p.payment_status", "p.amount",
        "s.ticket_id", "s.issue_type", "s.ticket_date", "s.resolution_status",
        "w.page_viewed", "w.device_type", "w.session_time"
    )
)

customer360.write.format("delta").mode("overwrite").saveAsTable("gold.customer360")
